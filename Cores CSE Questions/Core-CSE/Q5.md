## Q1. Explain LRU cache and its implementation by taking some examples and explaining all steps ?

## Answer:

A Least Recently Used (LRU) Cache organizes items in order of use, allowing you to quickly identify which item hasn't been used for the longest amount of time.

**Strengths:**
Super fast accesses. LRU caches store items in order from most-recently used to least-recently used. That means both can be accessed in O(1)O(1) time.

Super fast updates. Each time an item is accessed, updating the cache takes O(1)O(1) time.

**Weaknesses**
Space heavy. An LRU cache tracking nn items requires a linked list of length nn, and a hash map holding nn items. That's O(n)O(n) space, but it's still two data structures (as opposed to one).

An LRU cache is an efficient cache data structure that can be used to figure out what we should evict when the cache is full. The goal is to always have the least-recently used item accessible in O(1)O(1) time.

Accessing and Evicting
Putting things together, here are the steps we'd run through each time an item was accessed:

Look up the item in our hash map.

If the item is in the hash table, then it's already in our cache—this is called a "cache hit"

Use the hash table to quickly find the corresponding linked list node.

Move the item's linked list node to the head of the linked list, since it's now the most recently used (so it shouldn't get evicted any time soon).

If the item isn't in the hash table, we have a cache miss. We need to load the item into the cache:

Is our cache full? If so, we need to evict something to make room:

Grab the least-recently used cache item—it'll be at the tail of the linked list.

Evict that item from the cache by removing it from the linked list and the hash map.

Create a new linked list node for the item. Insert it at the head of the linked list.

Add the item to our hash map, storing the newly-created linked list node as the value.
